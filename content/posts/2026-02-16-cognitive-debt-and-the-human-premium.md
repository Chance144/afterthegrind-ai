---
title: "Cognitive Debt and the Human Premium"
date: 2026-02-16
draft: true
summary: "An MIT study finds heavy AI users show 55% lower cognitive engagement. Columbia research shows people value 'human-made' art 62% higher. Together, they reveal the real stakes of the AI transition: not just who loses their job, but who loses their mind."
tags: ["AI", "cognition", "higher education", "workforce", "human value"]
---

Something strange is happening on both sides of the AI divide. On one side, people who use AI heavily are thinking less. On the other, people are paying more for proof that a human thought at all. These two findings, from two very different labs, tell the same story. And it is not the story most people are talking about.

## The 55% Problem

An MIT Media Lab study, published in mid-2025, tracked 54 participants over four months. Three groups: one writing essays with ChatGPT, one using search engines, one using nothing but their own brains. The researchers monitored brain connectivity via EEG the entire time.

The results were not subtle. Heavy ChatGPT users showed up to 55% lower cognitive engagement than the unaided group. Worse, the deficit compounded over the four months. And when the AI group was reassigned to work without it, the reduced connectivity persisted. They struggled to recall their own arguments.

The researchers called it "cognitive debt." That phrase deserves more attention than it has received.

Cognitive debt is not the same as laziness or distraction. It describes a structural change in how the brain processes information when a powerful external system handles the hard parts. Think of it like financial debt: easy to accumulate, invisible until it compounds, and brutally difficult to reverse.

For anyone in higher education, this should land like a thunderclap. We are in the middle of integrating AI into every aspect of teaching and learning. We are redesigning curricula, rewriting policies, building AI literacy programs. All of that is necessary. But almost none of the conversation addresses what happens to the students who adopt these tools most enthusiastically. The ones who do everything right, by our new standards, might be the ones accumulating the most cognitive debt.

## The 62% Premium

Now consider a study from Columbia Business School, reported this week at the India AI Impact Summit. Researchers showed participants identical artworks. The only variable was a label: "human-made" or "AI-generated." People valued the human-labeled pieces 62% higher.

This is not nostalgia or Luddism. It is a market signal. When the supply of competent output explodes (and AI guarantees it will), the scarce resource is not competence. It is provenance. People want to know a human was in the loop, not because the output is necessarily better, but because human involvement means something beyond the artifact itself. It signals intention, risk, taste, accountability.

Put the two studies together and a picture emerges that neither captures alone. AI makes output cheap and cognition expensive. The more we offload thinking to machines, the rarer genuine human thinking becomes. And the rarer it becomes, the more people are willing to pay for it.

## What This Means for Business Schools

The India AI Impact Summit, which opened today in New Delhi, is framing AI as a resource allocation question: who gets it, how much, how fast. That framing matters. But it misses the second-order question that the MIT and Columbia studies raise together.

The question is not just whether your graduates can use AI. It is whether they can still think without it.

Business schools are currently in a race to integrate AI into every course, every project, every capstone. The logic is sound: students need to be fluent in the tools that will define their workplaces. Nobody argues with that. But fluency is not the same as dependence. And the MIT study suggests the line between them is thinner than anyone assumed.

Here is the tension: the students who will be most valuable in the job market are those who can leverage AI and maintain the cognitive independence that makes human judgment worth paying for. The 62% premium is not going away. If anything, as AI output becomes even more ubiquitous, the premium on verified human thought will increase.

That means business education needs a dual mandate. Teach AI fluency, yes. But also build what you might call cognitive resilience: the ability to think deeply, argue coherently, and make decisions under uncertainty without defaulting to a prompt.

## The Khosla Timeline

This matters more urgently than it might seem. Also at the AI Summit today, Vinod Khosla predicted that IT services and BPOs will "almost completely disappear" within five years. Microsoft AI CEO Mustafa Suleyman said last week that most white-collar tasks involving a computer will be automated within 18 months. The Atlantic ran a feature arguing America is not ready for what AI will do to jobs.

These predictions vary in specifics, but the direction is unanimous. A massive portion of the professional work that business schools currently prepare students for is going to be done by machines. Not in a decade. Now.

In that world, the graduates who will thrive are not the ones who can do what AI does, slightly slower. They are the ones who can do what AI cannot: exercise judgment in ambiguous situations, build trust with other humans, create things that carry the weight of genuine intention. The ones, in other words, who avoided cognitive debt while everyone around them was running up the tab.

## The Real Curriculum Question

None of this means AI should be kept out of classrooms. That ship sailed. But it does mean the conversation about AI in education needs to grow up. Right now, most institutions are asking a first-order question: "How do we teach students to use AI?" The more important question, the one that the MIT data demands we take seriously, is: "How do we teach students to use AI without losing the cognitive capacities that make them irreplaceable?"

That is a harder question. It requires rethinking not just what tools students use, but what kinds of assignments build genuine understanding versus what kinds simply generate polished output. It means valuing the struggle of thinking, not just the product of it. It means treating the brain like what it is: a muscle that atrophies when you stop using it.

The human premium is real. But it only accrues to humans who have kept the machinery of thought in working order. For educators, for business school deans, for anyone designing the next generation of professional training, the message from this week's research is clear: the hardest thing about the AI transition is not learning to use the tools. It is remembering how to think without them.
