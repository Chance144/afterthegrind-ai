---
title: "Business Schools Are All-In on AI. That's the Easy Part."
date: 2026-02-15
draft: true
summary: "NYU Stern launches an AI MBA specialization. AACSB publishes a framework. The NYT warns universities are being devoured by AI companies. Everyone agrees AI belongs in business education. Nobody agrees on what that actually means."
tags: ["AI", "business schools", "higher education", "MBA", "workforce"]
---

There is a particular kind of consensus that should make you nervous. It is the kind where everyone agrees on the direction but nobody agrees on the destination. That is exactly where business schools find themselves with artificial intelligence in February 2026.

This past week brought a flurry of announcements that, taken together, paint a picture of an industry sprinting toward something it cannot quite see. NYU's Stern School of Business announced a new AI specialization for MBA students, complete with courses on AI agents and AI in marketing analytics. AACSB, the accrediting body that sets the standard for business education worldwide, published a collaborative framework for AI in business education with nearly 50 member schools contributing. Georgetown McDonough redesigned its entire MBA curriculum with AI and ethical leadership at the center. And the New York Times ran an op-ed warning that AI companies are "eating higher education," using universities as training grounds while claiming to support educators.

All of this happened in the span of a few days. And all of it points to the same uncomfortable truth: business schools know they need to teach AI. They just do not know what "teaching AI" means yet.

## The Curriculum Arms Race

Let's start with what is actually changing. NYU Stern's new specialization includes nine courses, ranging from "Foundations of AI Agents" to "Leading in the Age of AI." Professor Ilan Lobel described the goal as turning MBA students "from being disrupted by AI into being AI disruptors." That is a great sound bite. But look at what it implies: the default assumption is that an MBA graduate, without specific AI training, will be disrupted. The degree itself is no longer sufficient armor.

Stern is not alone. The AACSB report reveals a clear shift across dozens of business schools. The defensive posture of 2023 and 2024, when many institutions banned or restricted AI tools, has given way to integration. Miami University's Farmer School now asks students to use AI and then verify its outputs. The University of Richmond frames AI as an employer-driven imperative. The message from nearly every school is the same: we have moved past the question of whether AI belongs in the classroom.

The new question is how deep it goes.

## The Depth Problem

This is where things get interesting, and where the consensus starts to fracture. There are roughly three camps emerging in business education.

**Camp One: AI as a Tool.** These schools treat AI the way they treat Excel or Tableau. Learn the interface. Know how to prompt. Understand the outputs. Move on. This is the most common approach and the easiest to implement. It requires minimal disruption to existing courses and faculty expertise. It is also, frankly, insufficient.

**Camp Two: AI as a Discipline.** Stern's new specialization lives here. So does Columbia's AI and Data Analytics pathway and Northwestern Kellogg's MBAi program. These schools are building dedicated tracks where students study AI as a subject in its own right, complete with courses on machine learning, data infrastructure, and increasingly, agentic systems. This approach is more ambitious but still treats AI as something you study alongside your real major.

**Camp Three: AI as the Environment.** This is the rarest and most radical approach. It means redesigning every course, not just the AI electives, around the assumption that AI is present in every professional context. Marketing courses assume AI-generated content is the norm. Finance courses assume AI-driven analysis is baseline. Strategy courses wrestle with what competitive advantage means when every firm has the same AI capabilities. Georgetown's curriculum redesign hints at this direction, but no school has fully committed.

The gap between Camp One and Camp Three is enormous. And most business schools are still firmly in Camp One, with a few elective courses sprinkled on top for good measure.

## The Trust Paradox

The AACSB report surfaces another tension that deserves more attention: the question of trust. Most business schools report high levels of trust in students regarding AI use. Faculty are essentially leaving it to students to decide when and how to use generative AI, even on assignments where it could do most of the work.

This is either admirably progressive or dangerously naive, depending on your perspective. The report itself notes the paradox. Schools want students to develop foundational skills without AI assistance. They also want students to become proficient AI users. These goals coexist uneasily. As one professor put it: "You want to teach them AI skills, but you also need them to learn basic skills without generative AI tools. How do you set that line?"

Nobody has a good answer. Detection tools have improved, but the fundamental tension remains. You cannot simultaneously tell students that AI is essential to their careers and that using it on assignments is cheating. The cognitive dissonance is becoming untenable, and students know it.

## The NYT Warning

Meanwhile, the New York Times op-ed drops a cold bucket of reality on the whole enterprise. The piece argues that AI companies are not partners to higher education but predators, using university relationships to gain legitimacy, access student data, and advance their own research agendas. It notes that OpenAI developed AI detection technology that was 99.9 percent accurate and then chose not to release it, presumably because doing so would undermine adoption of its own tools.

Whether or not you agree with the op-ed's framing, it raises a question that business schools should be asking more loudly: whose interests are being served? When a school partners with OpenAI to give every student ChatGPT access, is that a pedagogical decision or a market capture strategy? When AI companies provide free tools and training to faculty, what are they getting in return?

Business schools teach their students to analyze power dynamics, incentive structures, and information asymmetries in every industry. They should apply those same frameworks to the AI companies courting them.

## What Actually Matters

Here is what I think gets lost in the rush to add AI to the curriculum: the most important skills for the post-AI workplace are not technical. They are interpretive, integrative, interpersonal, and imaginative. They are the skills that let you figure out what questions to ask, not just how to prompt a model. They are the skills that let you synthesize conflicting information from multiple sources, including AI-generated analysis that may be confident and wrong.

Adding an AI specialization is fine. Building AI literacy into core courses is better. But the real work is harder than either of those things. It means teaching students to think critically about a technology that is designed to sound authoritative. It means preparing them for a world where their value comes not from knowing things, but from judging, connecting, and creating in ways that AI cannot replicate.

Business schools are all-in on AI. That was the easy decision. The hard decisions are just beginning.
