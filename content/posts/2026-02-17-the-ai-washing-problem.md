---
title: "The AI-Washing Problem: When Companies Blame the Robot"
date: 2026-02-17T06:00:00-08:00
draft: true
summary: "Tech layoffs keep climbing and CEOs keep pointing at AI. But a growing body of evidence suggests the robot is taking the blame for decisions that have nothing to do with automation."
tags: ["AI", "workforce", "layoffs", "business", "higher education"]
---

Here is a number that should make you uncomfortable: 30,700 tech workers have lost their jobs so far in 2026. Of those, roughly 1,430 have been explicitly tied to AI adoption. That leaves about 29,000 people whose layoffs had nothing to do with artificial intelligence, even though the word "AI" appeared somewhere in the press release.

Welcome to the age of AI-washing.

The term borrows from "greenwashing," the well-documented practice of companies slapping environmental language on business decisions that are fundamentally about cost-cutting. AI-washing works the same way. A company restructures because of declining revenue, shifts strategy because a product line failed, or simply decides to do more with fewer people. But instead of saying that, they invoke the magic letters: A-I.

It sounds better. It sounds inevitable. It sounds like the future rather than a spreadsheet.

## The 18-Month Prophecy

This week, Microsoft's CEO of AI made headlines by predicting that white-collar jobs would be "fully automated" within 18 months. It is a bold claim, and it landed the same week that a detailed analysis showed the promise of AI replacing software developers has "failed to deliver significant workforce reductions." Predictions from 2023 that AI would replace up to 80% of developers have quietly evaporated. The code still needs humans. The meetings still need humans. The judgment calls definitely still need humans.

But the prediction serves a purpose. When a tech executive says automation is 18 months away, they are not making a forecast. They are making an argument. They are telling shareholders that investment in AI infrastructure will pay off. They are telling employees to accept change. They are telling the market that this company is on the right side of history.

Whether the timeline is accurate matters less than whether people believe it.

## What the Data Actually Shows

Quartz reported this week on the growing practice of "AI-washing" layoffs, noting that companies routinely lump together automation-driven cuts with strategic realignments, market corrections, and plain old cost reduction. One analyst put it bluntly: of 500 eliminated positions at a typical firm, maybe 150 are genuinely attributable to automation of specific back-office functions. The remaining 350 reflect shifting market conditions and strategic decisions that would have happened with or without ChatGPT.

This matters for anyone trying to understand the labor market. If you are a business student reading these headlines, you might conclude that no white-collar job is safe, that the best strategy is to pivot into AI engineering or give up entirely. Neither conclusion is warranted by the evidence.

The reality is messier and more interesting. AI is genuinely transforming some roles. Data entry, routine document processing, basic code generation, first-pass customer service: these tasks are being automated at scale. But "automating tasks" is not the same as "eliminating jobs." Most jobs are bundles of tasks, and the ones that disappear tend to be the ones nobody enjoyed doing in the first place.

## The Business School Response

The Financial Times reported this week that business schools are scrambling to develop clear AI guidelines, and the picture is not encouraging. As David Marchick, dean of Kogod School of Business at American University, put it: "AI creates a real risk of disintermediation of traditional education. Universities need to adapt to include AI fluency and literacy in every aspect of teaching and learning. But it's very hard. There's no road map."

Meanwhile, the University of Georgia launched a comprehensive campus AI pilot, and researchers are publishing work on "Heart Skills," the emotional literacy competencies like empathy, assertiveness, and self-awareness that AI cannot replicate. The argument is straightforward: if machines handle the analytical grunt work, the differentiator becomes your ability to connect, persuade, lead, and make ethical judgments under uncertainty.

This is exactly right, and it is exactly what gets lost in the AI-washing noise.

When companies frame every layoff as an AI story, they create a narrative in which human skills are depreciating assets. That narrative is wrong. What is actually depreciating is routine cognitive labor, the kind of work that was already boring, already being offshored, already being squeezed by every productivity tool since the spreadsheet.

## The Real Conversation We Should Be Having

The question is not "will AI take your job?" The question is "which parts of your job are you willing to let go of, and what will you do with the time you get back?"

For business educators, this reframing is essential. Students who graduate believing they are competing against AI will make defensive career choices. They will optimize for tasks machines already do well. They will try to out-compute the computer. That is a losing strategy.

Students who graduate understanding that AI handles the grind while humans handle the meaning will make very different choices. They will invest in judgment, creativity, relationship-building, and the kind of integrative thinking that connects dots across domains. They will not be threatened by automation because they will not be doing automatable work.

The AI-washing problem is not just a corporate communications issue. It is an educational one. Every exaggerated headline about AI replacing all jobs teaches young professionals the wrong lesson. It teaches them that the future belongs to machines, when the evidence keeps showing that the future belongs to people who know how to work alongside them.

The 30,700 people who lost their jobs this year deserve honest accounting. Some of those cuts were driven by genuine automation. Many were not. Conflating the two does not help workers, does not help students, and does not help anyone except the executives who would rather blame the robot than explain the spreadsheet.

The grind is ending. But the work that matters? That is just getting started.
