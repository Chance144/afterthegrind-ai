<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=en-us dir=ltr><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>25 Papers Later - After the Grind</title>
<meta name=theme-color><meta name=description content="What 25 years of studying how humans think, feel, and decide taught me about our value in a machine age. A personal reflection on a research arc from trade dress to moral outrage."><meta name=author content="Andrew Perkins"><link rel="preload stylesheet" as=style href=https://afterthegrind.ai/main.min.55f67b3b9482b33ca2648823a61f5e76f43181837316a5e844e85db17499eb47.css integrity="sha256-VfZ7O5SCszyiZIgjph9edvQxgYNzFqXoROhdsXSZ60c="><link rel=preload as=image href=https://afterthegrind.ai/theme.png><link rel=preload as=image href=https://afterthegrind.ai/twitter.svg><link rel=preload as=image href=https://afterthegrind.ai/github.svg><link rel=preload as=image href=https://afterthegrind.ai/linkedin.svg><link rel=preload as=image href=https://afterthegrind.ai/rss.svg><script defer src=https://afterthegrind.ai/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://afterthegrind.ai/favicon.ico><link rel=apple-touch-icon href=https://afterthegrind.ai/apple-touch-icon.png><meta name=generator content="Hugo 0.142.0"><meta itemprop=name content="25 Papers Later"><meta itemprop=description content="What 25 years of studying how humans think, feel, and decide taught me about our value in a machine age. A personal reflection on a research arc from trade dress to moral outrage."><meta itemprop=datePublished content="2026-02-14T00:00:00+00:00"><meta itemprop=dateModified content="2026-02-14T00:00:00+00:00"><meta itemprop=wordCount content="1250"><meta itemprop=keywords content="Research,Personal,Consumer Psychology,AI,Career Reflection"><meta property="og:url" content="https://afterthegrind.ai/posts/2026-02-14-25-papers-later/"><meta property="og:site_name" content="After the Grind"><meta property="og:title" content="25 Papers Later"><meta property="og:description" content="What 25 years of studying how humans think, feel, and decide taught me about our value in a machine age. A personal reflection on a research arc from trade dress to moral outrage."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-14T00:00:00+00:00"><meta property="article:modified_time" content="2026-02-14T00:00:00+00:00"><meta property="article:tag" content="Research"><meta property="article:tag" content="Personal"><meta property="article:tag" content="Consumer Psychology"><meta property="article:tag" content="AI"><meta property="article:tag" content="Career Reflection"><meta name=twitter:card content="summary"><meta name=twitter:title content="25 Papers Later"><meta name=twitter:description content="What 25 years of studying how humans think, feel, and decide taught me about our value in a machine age. A personal reflection on a research arc from trade dress to moral outrage."><link rel=canonical href=https://afterthegrind.ai/posts/2026-02-14-25-papers-later/></head><body class="bg-(--bg) text-black antialiased duration-200 ease-out [-webkit-tap-highlight-color:transparent] dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-(--w) px-8 whitespace-nowrap lg:justify-center"><div class="relative z-50 flex items-center ltr:mr-auto rtl:ml-auto"><a class="-translate-y-[1px] text-2xl font-medium" href=https://afterthegrind.ai/>After the Grind</a><div class="btn-dark text-[0px] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden ltr:-mr-8 rtl:-ml-8" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"rgb(0 0 0 / 85%)":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full flex-col justify-center bg-(--bg) pb-16 duration-200 select-none lg:static lg:h-auto lg:flex-row lg:bg-transparent! lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/tags/>Topics</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/book/>The Book</a></nav><nav class="mt-12 flex justify-center space-x-10 lg:mt-0 lg:items-center ltr:lg:ml-14 rtl:space-x-reverse rtl:lg:mr-14 dark:invert"><a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./twitter.svg) href=https://twitter.com/ target=_blank rel=me>twitter</a>
<a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/ target=_blank rel=me>github</a>
<a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./linkedin.svg) href=https://linkedin.com/in/andrewperkins target=_blank rel=me>linkedin</a>
<a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./rss.svg) href=https://afterthegrind.ai/index.xml target=_blank rel=alternate>rss</a></nav></div></header><main class="prose prose-neutral dark:prose-invert relative mx-auto min-h-[calc(100vh-9rem)] max-w-(--w) px-8 pt-14 pb-16"><article><header class=mb-14><h1 class="my-0! pb-2.5">25 Papers Later</h1><div class="text-xs antialiased opacity-60"><time>Feb 14, 2026</time></div></header><section><p>My first published paper was about wine labels.</p><p>It was 2000. I was working with colleagues at Washington State University on trade dress, the visual packaging that makes consumers think two products are basically the same thing. We showed that when wine bottles look alike, people perceive the products inside as substantially similar. It was a clean, tidy study. Straightforward. Nothing revolutionary.</p><p>But looking back, that paper was asking a question I&rsquo;d spend the next 25 years circling: how do surface signals shape the judgments people make? And when do those signals mislead?</p><p>I didn&rsquo;t know it then. I didn&rsquo;t have the language for it. But that question, the gap between what we see and what we conclude, between the signal and the truth, turns out to be the central question of the AI age.</p><h2 id=the-implicit-mind>The Implicit Mind</h2><p>By 2005, I was deep into implicit cognition. My work with Mark Forehand on celebrity voice-overs showed something fascinating: when consumers hear a celebrity&rsquo;s voice in an ad but don&rsquo;t consciously recognize who it is, their attitudes shift through assimilation. They absorb the celebrity&rsquo;s qualities without knowing it. But the moment they identify the voice, the effect reverses. Explicit recognition triggers contrast and skepticism.</p><p>Think about what that means. The same stimulus produces opposite effects depending on whether you&rsquo;re aware of it. The conscious mind and the unconscious mind don&rsquo;t just differ in degree. They can point in opposite directions.</p><p>This became a throughline. In 2006, I published work decomposing the implicit self-concept, showing that the way we unconsciously associate ourselves with attributes is driven by both meaning and raw emotional valence, and these are separable forces. In 2012, we demonstrated that nonvolitional self-association, seeing your name next to a brand in a social media banner ad you barely noticed, could shift your attitudes and choices. You didn&rsquo;t choose to connect with that brand. Your mind did it for you.</p><p>I spent years in this territory. Implicit attitudes. Automatic social comparisons. The machinery humming beneath conscious awareness. It was intellectually thrilling. It was also, I realize now, training me to understand something that would matter enormously later: humans are not the rational agents our business models pretend they are. We are creatures of context, association, feeling, and habit. And that&rsquo;s not a bug. It&rsquo;s the feature.</p><h2 id=bodies-identity-and-who-gets-to-be-human>Bodies, Identity, and Who Gets to Be Human</h2><p>Around 2009, my research took a turn I didn&rsquo;t expect. I started studying how bodies become sites of judgment. With Mikki Hebl and Eden King, I explored ethnic differences in obesity stigma, how Black and White women relate differently to thin ideals and what that means for how they&rsquo;re treated. With the pharmaceutical study, we showed that even tiny promotional items, a branded pen, a coffee mug, could shift medical students&rsquo; implicit preferences toward brand-name drugs. The signals were small. The effects were real.</p><p>This thread deepened over the next decade. Health-based weight stereotypes in advertising. How larger-bodied women are portrayed in health campaigns, and the radical difference between showing a body as a &ldquo;process&rdquo; versus an &ldquo;object.&rdquo; Feminists and their relationship with premium beauty products. Extended-sized clothing lines and what they signal about a retailer&rsquo;s values.</p><p>Paper by paper, I kept finding the same thing: the way we represent humans matters enormously. Framing matters. Language matters. The choice between portraying someone as a full person or as a category changes everything downstream, from attitudes to intentions to actual behavior.</p><p>I didn&rsquo;t connect this to AI until much later. But I should have seen it sooner.</p><h2 id=power-nostalgia-awe-and-cold-drinks>Power, Nostalgia, Awe, and Cold Drinks</h2><p>Research goes where curiosity takes it, and mine took me to some unexpected places. With Shuying Bi, I studied how feeling powerless drives people toward nostalgic products, reaching for the comfort of the familiar when the future feels uncertain. We found that powerlessness creates a sense of future uncertainty, and nostalgia becomes a coping mechanism. Self-acceptance moderates the whole thing: people who&rsquo;ve made peace with themselves don&rsquo;t need the past as badly.</p><p>We also discovered that feeling powerful makes people prefer cold-imagery ads. The mechanism? Power increases social distance motivation, and coldness maps onto that psychological distance. Your boss literally has different aesthetic preferences than you do, and it&rsquo;s not arbitrary. It&rsquo;s embodied cognition at work.</p><p>With Khayyam Ahmmad, I explored how awe, that feeling of vastness and self-transcendence, shapes tolerance for ambiguity in consumer choice. Awe does two things simultaneously: it makes you feel small, and it makes you feel connected to something larger. These pull in opposite directions when you&rsquo;re facing an ambiguous decision.</p><p>These studies might seem scattered. They&rsquo;re not. Every one of them is a window into the same room: the extraordinary complexity of human judgment. We are influenced by power, temperature, physical size, emotional state, group identity, and a hundred other forces we barely notice. And we somehow navigate all of it, simultaneously, in real time, while also holding a conversation and drinking coffee.</p><p>No machine does this. No machine is close to doing this.</p><h2 id=moral-outrage-and-the-ingroup>Moral Outrage and the Ingroup</h2><p>My most recent work, published in 2026 with Jeff Rotman and Americus Reed, examines when moral outrage leads to public online condemnation. The finding that struck me hardest: it depends on whether the transgressor is perceived as part of your ingroup. We don&rsquo;t just react to moral violations. We react to moral violations in context, filtered through identity, belonging, and the social meaning of speaking up.</p><p>This paper, more than any other, crystallized something for me. Human moral judgment is not a calculation. It is a deeply social act, shaped by who we are, who we&rsquo;re with, and what speaking up means for our place in the group. It is contextual, relational, and irreducibly human.</p><p>AI can flag content that violates a policy. It cannot understand why a community is outraged, whether that outrage is justified, or what healing would require. That&rsquo;s not a technical limitation that will be solved with more training data. It&rsquo;s a category difference.</p><h2 id=what-25-years-taught-me>What 25 Years Taught Me</h2><p>Here&rsquo;s what I&rsquo;ve learned from studying humans for a quarter century.</p><p>We are not simple. We are not consistent. We are not rational in the way that models assume. We are influenced by things we don&rsquo;t notice, motivated by needs we can&rsquo;t articulate, and capable of judgment calls that integrate more variables than any system can track.</p><p>And all of that, every bit of it, is what makes us valuable in an age of machines.</p><p>When I wrote <em>After the Grind</em>, I argued that human value lives in four domains: the Interpretive, the Integrative, the Interpersonal, and the Imaginative. What I didn&rsquo;t say explicitly, but what I hope this essay makes clear, is that I didn&rsquo;t arrive at that framework in a vacuum. It grew out of 25 years of watching humans be gloriously, maddeningly, irreducibly complex.</p><p>The implicit mind that shifts without our permission. The body that shapes our judgments in ways we&rsquo;d never guess. The moral intuitions that depend on context and identity. The way power changes our aesthetic preferences and nostalgia comforts our uncertainty. None of this is programmable. None of this is reducible to training data. All of it is what we bring to the table.</p><p>I started with wine labels. I ended up writing a book about the future of human work. The throughline, I see now, was always the same question: what do humans do that can&rsquo;t be faked, automated, or approximated?</p><p>Twenty-five papers later, I have my answer. Everything that matters.</p></section><footer class="mt-12 flex flex-wrap"><a class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://afterthegrind.ai/tags/research>research</a><a class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://afterthegrind.ai/tags/personal>personal</a><a class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://afterthegrind.ai/tags/consumer-psychology>consumer psychology</a><a class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://afterthegrind.ai/tags/ai>AI</a><a class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://afterthegrind.ai/tags/career-reflection>career reflection</a></footer><nav class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg leading-[1.2]! *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"><a class="justify-end pl-3 ltr:ml-auto rtl:mr-auto" href=https://afterthegrind.ai/posts/2026-02-14-agents-and-the-work-to-signal-ratio/><span>Agents and the Work-to-Signal Ratio</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a></nav></article></main><footer class=footer><p>© 2026 Andrew Perkins</p></footer></body></html>